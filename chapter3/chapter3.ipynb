{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章: 正規表現\n",
    "\n",
    "Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzがある．\n",
    "\n",
    "* 1行に1記事の情報がJSON形式で格納される\n",
    "* 各行には記事名が”title”キーに，記事本文が”text”キーの辞書オブジェクトに格納され，そのオブジェクトがJSON形式で書き出される\n",
    "* ファイル全体はgzipで圧縮される\n",
    "\n",
    "以下の処理を行うプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. JSONデータの読み込み\n",
    "Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "output_text = ''\n",
    "with gzip.open('jawiki-country.json.gz', 'r') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        if article['title'] == 'イギリス':\n",
    "            output_text = article['text']\n",
    "\n",
    "with open('output/q20.txt', 'w', encoding='utf8') as f:\n",
    "    f.write(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. カテゴリ名を含む行を抽出\n",
    "記事中でカテゴリ名を宣言している行を抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\[{2}Category:(.+)\\]{2}')\n",
    "target_lines = [line for line in all_lines if re.search(pattern, line)]\n",
    "\n",
    "with open('output/q21.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines(target_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. カテゴリ名の抽出\n",
    "記事のカテゴリ名を（行単位ではなく名前で）抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\[{2}Category:(.+)\\]{2}')\n",
    "target_lines = [line.replace('[[', '').replace('Category:','').replace('|*', '').replace(']]', '').replace('|元', '') for line in all_lines if re.search(pattern, line)]\n",
    "\n",
    "with open('output/q22.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines(target_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. セクション構造\n",
    "記事中に含まれるセクション名とそのレベル（例えば”== セクション名 ==”なら1）を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'^=+.*=+$')\n",
    "target_texts = [line.replace('=', '').rstrip() + '\\t' + str(line.count('=') // 2 - 1) for line in all_lines if re.search(pattern, line)]\n",
    "\n",
    "with open('output/q23.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(target_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. ファイル参照の抽出\n",
    "記事から参照されているメディアファイルをすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'ファイル:(.+?)\\|')\n",
    "target_texts = [re.findall(pattern, line)[0] for line in all_lines if re.findall(pattern, line)]\n",
    "\n",
    "with open('output/q24.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(target_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. テンプレートの抽出\n",
    "記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\|(.+)\\s=\\s*(.+)')\n",
    "target_fields = {}\n",
    "for line in all_lines:\n",
    "    search_result = re.search(pattern, line)\n",
    "    if search_result:\n",
    "        target_fields[search_result.groups()[0]] = search_result.groups()[1]\n",
    "\n",
    "with open('output/q25.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(target_fields, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. 強調マークアップの除去\n",
    "25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: [マークアップ早見表](http://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\|(.+)\\s=\\s*(.+)')\n",
    "pattern_emphasis = re.compile(r'\\'{2,5}(.+?)\\'{2,5}')\n",
    "target_fields = {}\n",
    "for line in all_lines:\n",
    "    search_result = re.search(pattern, line)\n",
    "    if search_result:\n",
    "        value = search_result.groups()[1]\n",
    "        value = re.sub(pattern_emphasis, '\\\\1', value) # マッチ結果から、強調マークアップを除去\n",
    "        target_fields[search_result.groups()[0]] = value\n",
    "\n",
    "with open('output/q26.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(target_fields, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. 内部リンクの除去\n",
    "26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: [マークアップ早見表）](http://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\|(.+)\\s=\\s*(.+)')\n",
    "pattern_emphasis = re.compile(r'\\'{2,5}(.+?)\\'{2,5}')\n",
    "pattern_inner_link = re.compile(r'\\[\\[(?:[^|]*?\\|)??([^|]*?)\\]\\]')\n",
    "pattern_inner_link2 = re.compile(r'\\[\\[(?:[^|]*?\\|)(\\{\\{(?:.*?)\\}\\}*?)\\]\\]') # 表示文字の箇所にlangテンプレートを含むパターン（国歌フィールド）\n",
    "target_fields = {}\n",
    "for line in all_lines:\n",
    "    search_result = re.search(pattern, line)\n",
    "    if search_result:\n",
    "        value = search_result.groups()[1]\n",
    "        value = re.sub(pattern_emphasis, '\\\\1', value) # マッチ結果から、強調マークアップを除去\n",
    "        value = re.sub(pattern_inner_link, '\\\\1', value) # 内部リンクマークアップを除去\n",
    "        value = re.sub(pattern_inner_link2, '\\\\1', value) # 内部リンクマークアップを除去\n",
    "        target_fields[search_result.groups()[0]] = value\n",
    "\n",
    "with open('output/q27.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(target_fields, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. MediaWikiマークアップの除去\n",
    "27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "with open('output/q20.txt', 'r', encoding='utf8') as f:\n",
    "    all_lines = [line for line in f]\n",
    "\n",
    "pattern = re.compile(r'\\|(.+)\\s=\\s*(.+)')\n",
    "pattern_emphasis = re.compile(r'\\'{2,5}(.+?)\\'{2,5}')\n",
    "pattern_inner_link = re.compile(r'\\[\\[(?:[^|]*?\\|)??([^|]*?)\\]\\]')\n",
    "pattern_inner_link2 = re.compile(r'\\[\\[(?:[^|]*?\\|)(\\{\\{(?:.*?)\\}\\}*?)\\]\\]') # 表示文字の箇所にlangテンプレートを含むパターン（国歌フィールド）\n",
    "pattern_media_file = re.compile(r'\\[\\[(?:[^|]*?\\|)*?([^|]*?)\\]\\]')\n",
    "pattern_template_lang = re.compile(r'\\{\\{lang(?:[^|]*?\\|)*?([^|]*?)\\}\\}')\n",
    "pattern_template_tmp_link = re.compile(r'\\{\\{仮リンク\\|(.*?)(?:\\|.*?)*?\\}\\}')\n",
    "pattern_template_citeweb = re.compile(r'\\{\\{Cite web(?:|\\s)\\|(?:[^|]*?)*?(?:\\|title=(.*?))(?:\\|[^|]*?)*?\\}\\}')\n",
    "pattern_template_center = re.compile(r'\\{\\{center\\|(.*?)\\}\\}') # ファイルより先に除去（centerの表示文字の箇所にファイルが入っているため）\n",
    "pattern_outer_link = re.compile(r'\\[http(?:|s):\\/\\/(?:[^\\s]*?\\s)([^\\]]*?)\\]')\n",
    "pattern_br_ref_html = re.compile(r'<\\/?[br|ref][^>]*?>')\n",
    "target_fields = {}\n",
    "for line in all_lines:\n",
    "    search_result = re.search(pattern, line)\n",
    "    if search_result:\n",
    "        value = search_result.groups()[1]\n",
    "        value = re.sub(pattern_emphasis, '\\\\1', value) # マッチ結果から、強調マークアップを除去\n",
    "        value = re.sub(pattern_inner_link, '\\\\1', value) # 内部リンクマークアップを除去\n",
    "        value = re.sub(pattern_inner_link2, '\\\\1', value) # 内部リンクマークアップを除去\n",
    "        # MediaWikiマークアップを除去\n",
    "        value = re.sub(pattern_media_file, '\\\\1', value) # ファイル\n",
    "        value = re.sub(pattern_template_lang, '\\\\1', value) # langテンプレート\n",
    "        value = re.sub(pattern_template_tmp_link, '\\\\1', value) # 仮リンクテンプレート\n",
    "        value = re.sub(pattern_template_citeweb, '\\\\1', value) # Citewebテンプレート（title以外を除去）\n",
    "        value = re.sub(pattern_template_center, '\\\\1', value) # centerテンプレート\n",
    "        value = re.sub(pattern_outer_link, '\\\\1', value) # 外部リンク\n",
    "        value = re.sub(pattern_br_ref_html, '', value) # br, refタグ\n",
    "        target_fields[search_result.groups()[0]] = value\n",
    "\n",
    "with open('output/q28.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(target_fields, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. 国旗画像のURLを取得する\n",
    "テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: [MediaWiki API](http://www.mediawiki.org/wiki/API:Main_page/ja)の[imageinfo](https://www.mediawiki.org/wiki/API:Imageinfo)を呼び出して，ファイル参照をURLに変換すればよい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://upload.wikimedia.org/wikipedia/commons/a/ae/Flag_of_the_United_Kingdom.svg']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "with open('output/q28.json', 'r', encoding='utf8') as f:\n",
    "    national_flag_name = json.load(f)['国旗画像']\n",
    "\n",
    "session = requests.Session()\n",
    "URL = 'https://www.mediawiki.org/w/api.php'\n",
    "PARAMS = {\n",
    "    'action': 'query',\n",
    "    'format': 'json',\n",
    "    'prop': 'imageinfo',\n",
    "    'titles': 'File:' + national_flag_name,\n",
    "    'iiprop': 'url'\n",
    "}\n",
    "\n",
    "request = session.get(url=URL, params=PARAMS)\n",
    "data = request.json()\n",
    "pages = data['query']['pages']\n",
    "image_urls = [page['imageinfo'][0]['url'] for page in pages.values()]\n",
    "print(image_urls)\n",
    "\n",
    "with open('output/q29.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
